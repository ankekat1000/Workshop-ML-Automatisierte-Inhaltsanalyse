{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methoden-Workshop Machine Learning & AIA\n",
    "1. **Inhaltsanalyse-Daten einlesen uns ansehen** mit der Python-Bibliothek für Data Management ``pandas``.\n",
    "2. **Text in Features umwandeln** - mit ``sklearn``'s ``Vectorizer``.\n",
    "3. **Classification Functions** auswählen.\n",
    "4. Datensatz in **Train und Test Set** aufteilen.\n",
    "5. Die Funktion auf den Trainingsdaten **fitten** aka. **trainieren**.\n",
    "6. **Evaluieren** - Die Predictions mit der (manuellen) Codierung auf dem **Test Set abgleichen**.\n",
    "\n",
    "Dies ist die Extended Version des `ML-Workshop_Notebook_basic.ipynb` für die von euch, die noch ein bisschen mehr probieren wollen! Hinzugekommen sind:\n",
    "\n",
    "7. **Tf-Idf**-Gewichtung für die Worthäufigkeiten anstelle von absoluten Häufigkeiten.\n",
    "\n",
    "8. Ein paar **Pre-Processing-Optionen** mit dem `CountVectorizer`/`TfidfVectorizer`.\n",
    "\n",
    "9. Auswertung mit Camera Ready **Confusion Matrix** für euer Paper.\n",
    "\n",
    "011. Trainierten **Classifier speichern** (für dich und andere) und auf komplett neuen Daten **anwenden**.\n",
    "\n",
    "Auchtung! Für dieses Notebook müsst ihr die Packages `matplotlib` und `seaborn` installieren. \n",
    "\n",
    "Von: [anke.stoll@hhu.de](mailto:anke.stoll@hhu.de) <br>\n",
    "Last edit: 25.02.2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Von Excel nach Python und wieder zurück mit ``pandas``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Abkürzung für Faule und aus Konvention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daten einlesen - .csv or .txt oder Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wo liegt/wie heißt der Datensatz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data Sets/HateSpeech_Tweets_DataSet.csv\",\n",
    "                 sep=\",\") #Ändern bei Excel auf \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check out your data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HateSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Rosenmontag ist abgesagt. #Rapefugees also wi...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bitte nicht die #Türkei zum #EU-Mitglied mache...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wieso bekommen #rapefugees mehr als unsere Har...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Den verfluchten #Rapefugees den Krieg erklären...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>War das Wochenende im Ruhrpott unterwegs. Über...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet HateSpeech\n",
       "0  #Rosenmontag ist abgesagt. #Rapefugees also wi...        YES\n",
       "1  bitte nicht die #Türkei zum #EU-Mitglied mache...         NO\n",
       "2  Wieso bekommen #rapefugees mehr als unsere Har...         NO\n",
       "3  Den verfluchten #Rapefugees den Krieg erklären...        YES\n",
       "4  War das Wochenende im Ruhrpott unterwegs. Über...        YES"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #Zeigt die ersten 10 Zeilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HateSpeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Also ich finde, Europa ist sich einig wie noch...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>#dieanstalt #flüchtlinge und #Asylanten benöti...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Die Regierung hat nichts im Griff. Das gibt ho...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Das gerechte in #Deutschland ist ja, dass nich...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>#radikaler #Imam in #Dänemark ruft z #Steinigu...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Wo ist das Problem? Für Moslems ist es doch sc...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Simone #Peter hat seit 7 Monaten und weit über...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Bin gespannt auf #onebillionrising. Hoffentlic...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>#kipping ist so dumm! wenn #asylanten Wohnunge...</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Zukünft. #CDU Wähler aus #MEA marodieren auf M...</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet HateSpeech\n",
       "459  Also ich finde, Europa ist sich einig wie noch...         NO\n",
       "460  #dieanstalt #flüchtlinge und #Asylanten benöti...        YES\n",
       "461  Die Regierung hat nichts im Griff. Das gibt ho...         NO\n",
       "462  Das gerechte in #Deutschland ist ja, dass nich...         NO\n",
       "463  #radikaler #Imam in #Dänemark ruft z #Steinigu...         NO\n",
       "464  Wo ist das Problem? Für Moslems ist es doch sc...        YES\n",
       "465  Simone #Peter hat seit 7 Monaten und weit über...         NO\n",
       "466  Bin gespannt auf #onebillionrising. Hoffentlic...        YES\n",
       "467  #kipping ist so dumm! wenn #asylanten Wohnunge...         NO\n",
       "468  Zukünft. #CDU Wähler aus #MEA marodieren auf M...        YES"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10) #Oder die letzen 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df) #Anzahl der Zeilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NO     315\n",
       "YES    154\n",
       "Name: HateSpeech, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"HateSpeech\"].value_counts() #Überblick zu den Werten in einer Spalte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text zu Features - Unabhängigen Variablen programmieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die zweite super awesome Python Bibliothek heißt ``sklearn``. In dieser Bibliothek finden wir alles, was wir für ML brauchen. Auch das ML mit Text wird uns besonders einfach gemacht. In ``sklearn`` gibt es eine Unterabteilung ``feature_extraction.text``. Hier finden wir Funktionen, die uns das Umwandeln von Text zu Features (Unigramme oder N-Gramme) sehr einfach machen! \n",
    "\n",
    "Wir benutzen jetzt mal den ``TfidfVectorizer``. Dies ist eine etablierte und die beliebteste Gewichtung im ML mit Texte. Full documentation auf der [sklearn Website](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Oder lest [hier](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html) nach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All vectorizers have several parameters that you can modify. Der Tfidf Vectorizer kann genau so genutzt werden wie der `CountVectorizer`. Hier noch ein paar mehr Parameter, an denen man rumspielen kann!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1,1), #Hier: Nur Unigramme als Features.\n",
    "                      \n",
    "                      #Hiermit könnt ihr sehr seltene und sehr häufige Wörter im Datensatz entfernen.\n",
    "                      max_df=0.95,# In how many documents can a term occur max. E.g. in 95%.\n",
    "                      min_df=0.01,#How often must a term occur in the sample min. E.g. in 1% of the documents.\n",
    "                      \n",
    "                      #Hiermit könnt ihr eine Liste von Wörtern übergeben, die nicht berücksichtigt werden sollen.\n",
    "                      #Die Voreinstellung ist stop_words=None. Man kann auch einstellen stop_words=\"english\". \n",
    "                      #Oder man kann eine eigene Liste erstellen\n",
    "                      stop_words=[\"das\", \"und\", \"am\"]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets_vec = vec.fit_transform(df[\"Tweet\"]) \n",
    "#Wir wenden den Vectorizer auf der Spalte \"Tweet\" in unserem Datensatz an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<469x231 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4116 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tweets_vec # 469 tweets und 231 features (Oha, da sind ziemlich viele durch das Preprocessing verschwunden)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was sind unsere Features (UVs)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '2016',\n",
       " '500',\n",
       " 'ab',\n",
       " 'aber',\n",
       " 'abmerkeln',\n",
       " 'afd',\n",
       " 'alle',\n",
       " 'als',\n",
       " 'also',\n",
       " 'an',\n",
       " 'andere',\n",
       " 'angst',\n",
       " 'annewill',\n",
       " 'arbeit',\n",
       " 'ard',\n",
       " 'asyl',\n",
       " 'asylanten',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bald',\n",
       " 'bei',\n",
       " 'bekommen',\n",
       " 'besser',\n",
       " 'bevölkerung',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'cdu',\n",
       " 'christen',\n",
       " 'clausnitz',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dank',\n",
       " 'dann',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'dem',\n",
       " 'den',\n",
       " 'denen',\n",
       " 'der',\n",
       " 'des',\n",
       " 'deutsche',\n",
       " 'deutschen',\n",
       " 'deutschland',\n",
       " 'deutschlands',\n",
       " 'die',\n",
       " 'diebstahl',\n",
       " 'diese',\n",
       " 'doch',\n",
       " 'durch',\n",
       " 'dürfen',\n",
       " 'eigentlich',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'einfach',\n",
       " 'endlich',\n",
       " 'er',\n",
       " 'erst',\n",
       " 'es',\n",
       " 'eu',\n",
       " 'euro',\n",
       " 'europa',\n",
       " 'europas',\n",
       " 'falsch',\n",
       " 'findet',\n",
       " 'fluechtlinge',\n",
       " 'flüchtlinge',\n",
       " 'frau',\n",
       " 'frauen',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'geht',\n",
       " 'geld',\n",
       " 'gerade',\n",
       " 'gesagt',\n",
       " 'geschichte',\n",
       " 'gg',\n",
       " 'gibt',\n",
       " 'grenze',\n",
       " 'grenzen',\n",
       " 'griechenland',\n",
       " 'grüne',\n",
       " 'gut',\n",
       " 'gutmenschen',\n",
       " 'haben',\n",
       " 'handgranate',\n",
       " 'hartaberfair',\n",
       " 'hat',\n",
       " 'heute',\n",
       " 'hier',\n",
       " 'hungerstreik',\n",
       " 'ich',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'illner',\n",
       " 'im',\n",
       " 'immer',\n",
       " 'in',\n",
       " 'ins',\n",
       " 'is',\n",
       " 'islam',\n",
       " 'islamisierung',\n",
       " 'ist',\n",
       " 'ja',\n",
       " 'jahr',\n",
       " 'jetzt',\n",
       " 'kamen',\n",
       " 'kann',\n",
       " 'karneval',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'kiel',\n",
       " 'kinder',\n",
       " 'koelnhbf',\n",
       " 'kommen',\n",
       " 'kommt',\n",
       " 'krimigranten',\n",
       " 'kriminalität',\n",
       " 'kriminelle',\n",
       " 'köln',\n",
       " 'land',\n",
       " 'lanz',\n",
       " 'lassen',\n",
       " 'leben',\n",
       " 'legal',\n",
       " 'lieber',\n",
       " 'läuft',\n",
       " 'machen',\n",
       " 'macht',\n",
       " 'maischberger',\n",
       " 'mal',\n",
       " 'man',\n",
       " 'mehr',\n",
       " 'menschen',\n",
       " 'menschenwürde',\n",
       " 'merkel',\n",
       " 'merkelmussweg',\n",
       " 'migranten',\n",
       " 'millionen',\n",
       " 'mio',\n",
       " 'mir',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'männer',\n",
       " 'müssen',\n",
       " 'nach',\n",
       " 'nehmen',\n",
       " 'nein',\n",
       " 'neue',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'nie',\n",
       " 'noch',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'pegida',\n",
       " 'polizei',\n",
       " 'problem',\n",
       " 'rape',\n",
       " 'rapefugees',\n",
       " 'recht',\n",
       " 'refugees',\n",
       " 'refugeesnotwelcome',\n",
       " 'refugeeswelcome',\n",
       " 'regierung',\n",
       " 'rosenmontag',\n",
       " 'scharia',\n",
       " 'schnell',\n",
       " 'schon',\n",
       " 'schwimmbad',\n",
       " 'sein',\n",
       " 'sich',\n",
       " 'sicher',\n",
       " 'sie',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'soll',\n",
       " 'sollen',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'sophienhof',\n",
       " 'spd',\n",
       " 'syrien',\n",
       " 'tun',\n",
       " 'türkei',\n",
       " 'um',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'vergewaltigungen',\n",
       " 'verstoß',\n",
       " 'viel',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'wahlen',\n",
       " 'war',\n",
       " 'warum',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'wegen',\n",
       " 'weil',\n",
       " 'welt',\n",
       " 'wenn',\n",
       " 'wer',\n",
       " 'werden',\n",
       " 'widerstand',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirtschaft',\n",
       " 'wo',\n",
       " 'wohl',\n",
       " 'wollen',\n",
       " 'wurde',\n",
       " 'wählen',\n",
       " 'wählt',\n",
       " 'wäre',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zeit',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'über',\n",
       " 'überall']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names() #Das sind unsere Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ich habe hier ein Stück Code eingefügt, dass ihr nutzen könnt, um euch die Häufigkeiten der einzelnen Features in eurem Datensatz anzusehen.\n",
    "\n",
    "I used [this code from stuckoverflow](https://stackoverflow.com/questions/45805493/sorting-tfidfvectorizer-output-by-tf-idf-lowest-to-highest-and-vice-versa). Alternatively, you can try [this code](https://towardsdatascience.com/very-simple-python-script-for-extracting-most-common-words-from-a-story-1e3570d0b9d0) to get an overview of the most frequent words in your documents (before vectorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vec.get_feature_names()\n",
    "sums = Tweets_vec.sum(axis=0) \n",
    "\n",
    "data = []\n",
    "\n",
    "for col, term in enumerate(features):\n",
    "    data.append( (term, sums[0,col] ))\n",
    "\n",
    "df_ranks = pd.DataFrame(data, columns=['Feature','Count'])\n",
    "df_ranks.sort_values('Count', ascending=False, inplace=True) \n",
    "#Setzt den Parameter ascending auf True und ihr erhaltet die Sortierung nach Count aufsteigend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>die</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>asylanten</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>in</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>rapefugees</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>der</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Count\n",
       "46          die    218\n",
       "17    asylanten    203\n",
       "101          in    139\n",
       "164  rapefugees    120\n",
       "40          der    113"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranks.head() #Der Count ist diesmal relativ, nicht absolut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Den Classifier programmieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wissen nun, wie man Features im Bag-of-Words-Style (Wörter mit ihren Häufigkeiten) erstellt. Als Kategorie (AV, Label, Class) haben wir in unserem Datensatz Hate Speech (YES/NO). Jetzt berechnen wir einen Zusammenhang, heißt, wir versuchen, die Kategorie _Hate Speech_ durch unsere Feautures zu schätzen (klassifizieren)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als erstes müssen wir uns für eine Schätzfunktion - eine _Classification Function_ - entscheiden. Und zwar aus der Auswahl, die in der `sklearn` zu finden ist. Hier eine kleine Auswahl von Funktionen, die sich in der Forschung als geeignet herausgestellt haben. Jedoch muss man letztendlich durch Trail und Error herausfinden, welche sich am besteb eignet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression() \n",
    "#Ich entscheide mich für die LogReg mit Default Parameter-Einstellungen (daher ist die Klammer () leer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Den Datensatz in Train und Test Set aufteilen\n",
    "\n",
    "Als ersten teilen wir den Datensatz in Trainingsdaten und Testdaten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =df[\"HateSpeech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, #X is your pandas column with the documents.\n",
    "                                                    y, #y is your pandas coulmn with category.\n",
    "                                                    test_size=0.33,#Relative size of the test set. e.g. 33% \n",
    "                                                    random_state=42) #Chose a number to reproduce the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wird der Text in X in features umgewandlet (vektorisiert), wie wir es weiter oben gelernt haben. Achte darauf, zunächst nur die Texte im Train Set zu vektorisieren! Ich entscheide mich noch mal um, und zwar für absolute nicht gewichtete Häufigkeiten (`CountVectorizer`) und die folgenden Parametereinstellungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1,1), \n",
    "                      max_df=0.95,# In how many documents can a term occur max. E.g. in 95%.\n",
    "                      min_df=0.01,#How often must a term occur in the sample min. E.g. in 1% of the documents.\n",
    "                      \n",
    "                      stop_words=[\"das\", \"und\", \"am\", \"die\", \"der\"]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec = vec.fit_transform(X_train) #Do this ONLY ON X TRAIN !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<314x198 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2494 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec #314 Kommentare und 1987 Features (Unigramme hier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wird der Classifier trainiert! Das ist genau eine Zeile Code! Und geht mit unserem kleinen Train Set und Naive Bayes in Sekundenschnelle!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.fit(X_train_vec, y_train) #Fit the model, what means training. (13.9 ms dauert das Trainieren.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt lassen wir unser trainiertes (gefittetes) Modell Predictions auf dem Test Set machen, damit wir die klassifizierten Werte mit den tatsächlichen Labels vergleichen können.\n",
    "\n",
    "Vorher müssen die Texte im Test Set ebenfalls in Features transformiert werden. Nutze dafür nur die Funktion transform (nicht fit_transform) deines Vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = vec.transform(X_test)# Mache Predictions auf dem Test Set für die Evaluation. \n",
    "#Benutze die funtion transform, nicht fit_transform!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vec) #predict ist die Funktion, mit der die Predictions gemacht werden.\n",
    "#Diese werden im Objekt y_pred abgespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', 'YES', 'NO', 'YES', 'YES', 'NO', 'YES', 'YES', 'NO', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "       'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES', 'NO', 'YES', 'NO',\n",
       "       'NO', 'YES', 'NO', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO',\n",
       "       'NO', 'NO', 'YES', 'YES', 'YES', 'NO', 'NO', 'YES', 'NO', 'NO',\n",
       "       'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES',\n",
       "       'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES',\n",
       "       'NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'YES', 'NO',\n",
       "       'NO', 'NO', 'YES', 'YES', 'NO', 'NO', 'YES', 'YES', 'NO', 'NO',\n",
       "       'YES', 'NO', 'NO', 'NO', 'YES', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "       'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'YES', 'NO', 'YES'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred #Werfen wir schon mal einen Blick auf die klassifizierten Werte...Scheint jedenfalls geklappt zu haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation!\n",
    "\n",
    "Nun vergleichen wir die Ergebnisse des Classifiers mit den Labels auf dem Test Set. Hierfür importieren wir die ein paar Maße und Funktionen aus `sklear.metrics`, die wir für die Evaluation nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NO       0.72      0.83      0.77        99\n",
      "         YES       0.59      0.43      0.49        56\n",
      "\n",
      "    accuracy                           0.68       155\n",
      "   macro avg       0.65      0.63      0.63       155\n",
      "weighted avg       0.67      0.68      0.67       155\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This is a nice overview of the performance of your model in all categories (on the test set).\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code erstellt euch eine sehr schicke Confusion Matrix, die ihr als Pdf abspeichern könnt. Ihr müsst die Bibliotheken `seaborn` und `matplotlib` dafür installieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(array,index=[\"True No Hate\", \"True Hate\"],\n",
    "                  columns = [\"Predicted No Hate\", \"Predicted Hate\"])\n",
    "plt.figure(figsize = (7,5)\n",
    ")\n",
    "fig = sn.heatmap(df_cm, annot=True, annot_kws={\"fontsize\":16},\n",
    "                 cmap=plt.cm.Blues, cbar=True, linewidth=0.5, linecolor=\"black\")\n",
    "sn.set(font_scale=1.8)\n",
    "figure = fig.get_figure()    \n",
    "figure.savefig('my_cm.pdf', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Fehleranalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Kommentare wurden false positive klassifiziert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ein super Trick!\n",
    "false_positives = pd.DataFrame(X_test[y_test < y_pred])\n",
    "#false positives heißt, fälschlicherweise als Hate klassifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Manche sagen die #AfD Wähler sollen sich #schä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>#SternTV 24.02.16 soeben sofort weggezappt! Lü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>lieber #Horst #Seehofer,das #Geld aus #Saudiar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>#BeateUhse fördert #SCHARIA über Internet-Sexs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Es gibt keine #rapefugees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>#radikaler #Imam in #Dänemark ruft z #Steinigu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>#DeutscheBank sagt #Asylanten helfen der Wirts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Ein Soldat, der gegen Flüchtlinge ist und u.a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Ab jetzt heißt es nicht mehr Leben, sondern Üb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Das Geld ging für Lunchpakete der #rapefugees ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Glawischnig #Weltfrauentag: \"\"Ich bekämpfe kei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Ich zahle in einem christlichen Land jeden Mon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>#Kiel : der #Asylkult und seine Folgen, bald a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Wähler und Nichtwähler: Wir müssen uns wehren-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Pseudo #Sturmwarnung in #NRW zum Schutz deutsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Der blanke politische Schwachsinn:  #Sturmwarn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Kälte und schlechtes Wetter im Winter sind ein...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Tweet\n",
       "73   Manche sagen die #AfD Wähler sollen sich #schä...\n",
       "445  #SternTV 24.02.16 soeben sofort weggezappt! Lü...\n",
       "247  lieber #Horst #Seehofer,das #Geld aus #Saudiar...\n",
       "75   #BeateUhse fördert #SCHARIA über Internet-Sexs...\n",
       "386                          Es gibt keine #rapefugees\n",
       "463  #radikaler #Imam in #Dänemark ruft z #Steinigu...\n",
       "140  #DeutscheBank sagt #Asylanten helfen der Wirts...\n",
       "72   Ein Soldat, der gegen Flüchtlinge ist und u.a....\n",
       "412  Ab jetzt heißt es nicht mehr Leben, sondern Üb...\n",
       "302  Das Geld ging für Lunchpakete der #rapefugees ...\n",
       "304  Glawischnig #Weltfrauentag: \"\"Ich bekämpfe kei...\n",
       "382  Ich zahle in einem christlichen Land jeden Mon...\n",
       "324  #Kiel : der #Asylkult und seine Folgen, bald a...\n",
       "314  Wähler und Nichtwähler: Wir müssen uns wehren-...\n",
       "172  Pseudo #Sturmwarnung in #NRW zum Schutz deutsc...\n",
       "299  Der blanke politische Schwachsinn:  #Sturmwarn...\n",
       "367  Kälte und schlechtes Wetter im Winter sind ein..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ihr könnt euch die Tweets als .csv-Datei abspeichern, um sie zu später analysieren!\n",
    "false_positives.to_csv(\"False_positives.csv\", encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Welche Kommentare wurden false negative klassifiziert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55     lieber #Horst #Seehofer,der #Bayerische #Staat...\n",
       "78     #Asylanten betteln jetzt auch in den Nachbardö...\n",
       "408    Gute #Opfer von #Krimigranten & #Rapefugees ze...\n",
       "456    Vorhin hat jemand gefragt, wie es mit der #Isl...\n",
       "418    also die #fasnacht in diesem #jahr geht in die...\n",
       "93     Die #Islamisierung des #Abendlandes ist die sc...\n",
       "0      #Rosenmontag ist abgesagt. #Rapefugees also wi...\n",
       "464    Wo ist das Problem? Für Moslems ist es doch sc...\n",
       "30     Pöbelnde #Asylanten zeigen Kopf-ab-Gesten und ...\n",
       "238    Worauf warten diese scheiss #Flüchtlinge und #...\n",
       "406    #Diebstahl,#Einbruch,#sexuelle Übergriffe v. #...\n",
       "39     #besorgteGutmenschen regen sich auf :  #Khaled...\n",
       "301    Mensch #Gabriel, weil #Europa keine #Muslime h...\n",
       "117    Gerüchten zufolge finden sich in den Netzen de...\n",
       "124    Flüchtlinge zwangsweise in Privathaushalten ei...\n",
       "415    #IS-#Sympathisant aus #Darmstadt,#Werbe-#Video...\n",
       "277    #pegida ihr habt einen Maulwurf  Handabhacken ...\n",
       "434    Die Tussi war voll naiv. Nimmt südländische Mä...\n",
       "148    #Gutmenschen,die den #Islam unterstützen,werde...\n",
       "296    #Flüchtlinge und #Asylanten bzw. #Migranten si...\n",
       "460    #dieanstalt #flüchtlinge und #Asylanten benöti...\n",
       "454    #Sexuallkunde für #Flüchtlinge und #Migranten ...\n",
       "220    90% aller #Asylanten wollen nur deshalb nach D...\n",
       "312    Fünf #Männer und eine devote #Frau! Wie immer ...\n",
       "393    #Flüchtlinge & ´#Asylanten  sind perverse #Kin...\n",
       "298    #cdu kapiert es nicht! Alle in europa ausser c...\n",
       "46     #Deutschland übt #Karneval nach den Regeln der...\n",
       "126    Warum ist #deutschland nicht solidarisch mit d...\n",
       "24     #illner. erst hieß es, es kämen nur top Arbeit...\n",
       "31     Geld aus der Portokasse von #Merkel, oder doch...\n",
       "346    Ich will diese muslimische #Invasion hier nich...\n",
       "118    Ich würde gern mal eine #Sondersendung zur täg...\n",
       "Name: Tweet, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[y_test > y_pred] #Hier noch die false negatives, heißt, fälschlicherweise als No Hates klassifiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speichert euren trainierten Classifier für euch und die Nachwelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_saved_model.pickle']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_model = \"my_saved_model.pickle\"\n",
    "joblib.dump(model, filename_model) \n",
    "#model heißt hier das Objekt, in dem der gefittete Classifier gespeichert ist (s. oben)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch der Vectorizer (hier `vec` genannt, s. oben) muss mitgespeichert werden, da er an deinem Data Set die Features für die Classification gelernt hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_saved_vec.pickle']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_vec = \"my_saved_vec.pickle\"\n",
    "joblib.dump(vec, filename_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lade das gespeicherte Model + Vectorizer und mache Predictions auf 3 neuen Kommentaren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a saved model + the vectorizer\n",
    "model = joblib.load(\"my_saved_model.pickle\")\n",
    "vec = joblib.load(\"my_saved_vec.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_Comments = [\"Ich bin ein böser Hasskommentar\",\n",
    "                \"Ich hasse alle Menschen, fuck off\",\n",
    "                \"Ich liebe alle Menschen\"  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO', 'NO', 'NO'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vec.transform(New_Comments)) #Hmm...scheint unser Model wohl noch verbesserungswürdig! ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fertig!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
